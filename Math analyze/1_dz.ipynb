{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dee24c0-e9bf-427b-9b04-43e4c8220228",
   "metadata": {
    "id": "0dee24c0-e9bf-427b-9b04-43e4c8220228"
   },
   "source": [
    "# Домашнее задание №1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2345ed9-1018-4084-9636-7e7b92bd6c64",
   "metadata": {
    "id": "b2345ed9-1018-4084-9636-7e7b92bd6c64"
   },
   "source": [
    "## **Задача 1** \n",
    "\n",
    "#### Найдите экстремумы функции:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25e75bf-9d1e-4511-8846-8bfe99ae17f8",
   "metadata": {
    "id": "e25e75bf-9d1e-4511-8846-8bfe99ae17f8"
   },
   "source": [
    "$$\n",
    "f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8 .\n",
    "$$\n",
    "\n",
    "#### Распишите подробное решение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100abb6e",
   "metadata": {},
   "source": [
    "### Задача 1. Нахождение экстремумов функции — 5 баллов \n",
    "1.1. Вычисление частных производных - 1 балл \\\n",
    "1.2. Составление системы уравнений - 1 балл \\\n",
    "1.3. Решение системы уравнений - 1 балл \\\n",
    "1.4. Анализ второго порядка - 1 балл \\\n",
    "1.5. Запись результата и выводов - 1 балл\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb8b22a",
   "metadata": {},
   "source": [
    "### **1.1. Вычисление частных производных**\n",
    "В задаче представлена функция нескольких переменных $f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8$. Производные для функций нескольких переменных называются частными производными.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Частная производная первого порядка f от x: }\\hspace{1cm} f'_x &= 2 * 3 x^2 + 2 y + 2 z \\\\\n",
    "\n",
    "\\text{Частная производная первого порядка f от y: }\\hspace{1cm} f'_y &= 2 x + 2 y + 2 \\\\\n",
    "\n",
    "\\text{Частная производная первого порядка f от z: }\\hspace{1cm} f'_z &= 2 x + 2 z \n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020e455",
   "metadata": {},
   "source": [
    "### **1.2. Составление системы уравнений**\n",
    "Далее необходимо найти точки, в которых частные производные принимают нулевые значения. Для этого необходимо приравнять частные производные к нулю и составить систему уравнений из полученных равенств.\n",
    "\n",
    "Система уравнений частных производных, приравненных к нулю:\n",
    "$$\n",
    " \\begin{equation}\n",
    "    \\begin{cases}\n",
    "        6 x^2 + 2 y + 2 z = 0\\\\\n",
    "        2 x + 2 y + 2 = 0 \\\\\n",
    "        2 x + 2 z = 0\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ca072",
   "metadata": {},
   "source": [
    "### **1.3. Решение системы уравнений**\n",
    "Полученную систему уравнений будем решать методом подстановки.\n",
    "\n",
    "Для начала, так как все элементы системы имеют множители, кратные двум, упростим систему, поделив каждое уравнение на два:\n",
    "$$\n",
    " \\begin{equation}\n",
    " \\left.\n",
    "    \\begin{cases}\n",
    "        6 x^2 + 2 y + 2 z = 0\\\\\n",
    "        2 x + 2 y + 2 = 0 \\\\\n",
    "        2 x + 2 z = 0\n",
    "    \\end{cases}\n",
    "    \\right\\| :2 \\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        3 x^2 + y + z = 0\\\\\n",
    "        x + y + 1 = 0 \\\\\n",
    "        x + z = 0\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Далее из второго уравнения системы выразим $y$, из третьего уравнения выразим $z$, и подставим значения $y$ и $z$ в первое уравнение:\n",
    "$$\n",
    " \\begin{equation}\n",
    " \\left.\n",
    "    \\begin{cases}\n",
    "        3 x^2 + (- x - 1) + (-x) = 0\\\\\n",
    "        y = - x - 1 \\\\\n",
    "        z = - x\n",
    "    \\end{cases}\n",
    "    \\right.\\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        3 x^2 - x - 1 -x = 0\\\\\n",
    "        y = - x - 1 \\\\\n",
    "        z = - x\n",
    "    \\end{cases}\n",
    "    \\right.\\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        3 x^2 - 2 x - 1 = 0\\\\\n",
    "        y = - x - 1 \\\\\n",
    "        z = - x\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502466f9",
   "metadata": {},
   "source": [
    "Для нахождения значения $x$ необходимо решить квадратное уравнение $3 x^2 - 2 x - 1 = 0$, для этого воспользуемся теоремой Виета. Теорема Виета устанавливает связь между корнями квадратного уравнения $ax^{2}+bx+c=0$ и его коэффициентами: сумма корней $x_{1}+x_{2}$ равна $-b/a$, а произведение корней $x_{1}\\cdot x_{2}$ равно $c/a$.\n",
    "Для нашего случая:\n",
    "1) Cумма корней $\\hspace{0.5cm}x_{1}+x_{2} = -b/a = -(-2/3) = \\frac{2}{3}$\n",
    "\n",
    "2) Произведение корней $\\hspace{0.5cm}x_{1}\\cdot x_{2} = c/a = -1/3 = -\\frac{1}{3}$\n",
    "\n",
    "Далее методом подбора находим значения корней $x_{1}$, $x_{2}$:\n",
    "1) $x_{1} = 1$ \\\n",
    "Проверим, подставив значение в уравнение: $\\hspace{0.5cm}3*1^2 - 2*1 - 1 = 0 \\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} 3 - 2 - 1 = 0 \\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} 0 = 0$\n",
    "\n",
    "2) $x_{2} = -\\frac{1}{3}$ \\\n",
    "Проверим, подставив значение в уравнение: $\\hspace{0.5cm}3*(-\\frac{1}{3})^2 - 2*(-\\frac{1}{3}) - 1 = 0 \\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} 3 * \\frac{1}{9} + \\frac{2}{3} - 1 = 0\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm}\\frac{3}{9} + \\frac{2}{3} - 1 = 0\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} 1 - 1 = 0\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} 0 = 0$\n",
    "\n",
    "Далее найдем значения остальных переменных, подставив значения $x_{1}$, $x_{2}$ в систему уравнений:\n",
    "\n",
    "1) Для $x_{1} = 1$\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    " \\left.\n",
    "    \\begin{cases}\n",
    "        3 * 1^2 - 2 * 1 - 1 = 0\\\\\n",
    "        y = - 1 - 1 \\\\\n",
    "        z = - 1\n",
    "    \\end{cases}\n",
    "    \\right.\\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        0 = 0\\\\\n",
    "        y = - 2 \\\\\n",
    "        z = - 1\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    " \\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_{1} = 1;\\hspace{0.5cm} y_{1} = -2;\\hspace{0.5cm} z_{1} = -1\n",
    "$$\n",
    "2) Для $x_{2} = -\\frac{1}{3}$\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    " \\left.\n",
    "    \\begin{cases}\n",
    "        3 * (-\\frac{1}{3})^2 - 2 * (-\\frac{1}{3}) - 1 = 0\\\\\n",
    "        y = - (-\\frac{1}{3}) - 1 \\\\\n",
    "        z = - (-\\frac{1}{3})\n",
    "    \\end{cases}\n",
    "    \\right.\\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        0 = 0\\\\\n",
    "        y = -\\frac{2}{3} \\\\\n",
    "        z = \\frac{1}{3}\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    " \\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_{2} = -\\frac{1}{3};\\hspace{0.5cm} y_{2} = -\\frac{2}{3};\\hspace{0.5cm} z_{2} = \\frac{1}{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83ae909",
   "metadata": {},
   "source": [
    "### **1.4. Анализ второго порядка**\n",
    "Необходимое условие экстремума функции: если дифференцируемая функция $f(x, y, z)$ имеет экстремум в некоей точке, то все три производные первого порядка в данной точке равны нулю. Такую точку называют стационарной. В нашем случае стационарных точек две, назовем их $M_1$ и $M_2$: $M_1(1;-2;-1)$ и $M_2(-\\frac{1}{3};-\\frac{2}{3};\\frac{1}{3})$.\n",
    "Далее для проверки наличия экстремума необходимо найти все частные производные второго порядка, вычислить их в точках $M_1$ и $M_2$, составить матрицу Гессе.\n",
    "Найдем все частные производные второго порядка:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Частная производная первого порядка f от x: }\\hspace{1cm} f'_x &= 2 * 3 x^2 + 2 y + 2 z \\\\\n",
    "\n",
    "\\text{Частная производная первого порядка f от y: }\\hspace{1cm} f'_y &= 2 x + 2 y + 2 \\\\\n",
    "\n",
    "\\text{Частная производная первого порядка f от z: }\\hspace{1cm} f'_z &= 2 x + 2 z \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Частная производная второго порядка $f'_x$ по x: }\\hspace{1cm} f''_{xx} &= 12 x\\\\\n",
    "\n",
    "\\text{Частная производная второго порядка $f'_y$ по y: }\\hspace{1cm} f''_{yy} &= 2 \\\\\n",
    "\n",
    "\\text{Частная производная второго порядка $f'_z$ по z: }\\hspace{1cm} f''_{zz} &= 2 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Смешанная частная производная второго порядка $f'_x$ по y: }\\hspace{1cm} f''_{xy} &= 2\\\\\n",
    "\n",
    "\\text{Смешанная частная производная второго порядка $f'_x$ по z: }\\hspace{1cm} f''_{xz} &= 2\\\\\n",
    "\n",
    "\\text{Смешанная частная производная второго порядка $f'_y$ по x: }\\hspace{1cm} f''_{yx} &= 2\\\\\n",
    "\n",
    "\\text{Смешанная частная производная второго порядка $f'_y$ по z: }\\hspace{1cm} f''_{yz} &= 0\\\\\n",
    "\n",
    "\\text{Смешанная частная производная второго порядка $f'_z$ по x: }\\hspace{1cm} f''_{zx} &= 2\\\\\n",
    "\n",
    "\\text{Смешанная частная производная второго порядка $f'_z$ по y: }\\hspace{1cm} f''_{zy} &= 0\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Далее вычислим значания частных производных второго порядка в стационарных точках. В нашем случае все производные второго порядка, кроме $f''_{xx}$, равны константам, а значит и в стационарных точках они тоже будут равны константам. Вычислим значение $f''_{xx}$ в стационарных точках:\n",
    "\n",
    "1) В точке $M_1(1;-2;-1)$:\n",
    "$\n",
    "\\hspace{0.5cm}\n",
    "f''_{xx}(M_1) = 12 * 1 = 12\n",
    "$\n",
    "\n",
    "2) В точке $M_2(-\\frac{1}{3};-\\frac{2}{3};\\frac{1}{3})$:\n",
    "$\n",
    "\\hspace{0.5cm}\n",
    "f''_{xx}(M_2) = 12 * (-\\frac{1}{3}) = -4\n",
    "$\n",
    "\n",
    "Далее составим матрицы Гессе. В нашем случае их две:\n",
    "$$\n",
    "Hesse_1 =\n",
    "\\begin{pmatrix}\n",
    "f''_{xx}(M_1) & f''_{xy} & f''_{xz} \\\\\n",
    "f''_{yx} & f''_{yy} & f''_{yx} \\\\\n",
    "f''_{zx} & f''_{zy} & f''_{zz}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "12 & 2 & 2 \\\\\n",
    "2 & 2 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{pmatrix}\n",
    "$$    \n",
    "\n",
    "$$\n",
    "Hesse_2 =\n",
    "\\begin{pmatrix}\n",
    "f''_{xx}(M_2) & f''_{xy} & f''_{xz} \\\\\n",
    "f''_{yx} & f''_{yy} & f''_{yx} \\\\\n",
    "f''_{zx} & f''_{zy} & f''_{zz}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "-4 & 2 & 2 \\\\\n",
    "2 & 2 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{pmatrix}\n",
    "$$  \n",
    "\n",
    "Далее нужно вычислить угловые миноры. Это определители, которые \"разрастаются\" из левого верхнего угла.\n",
    "1) Для матрицы $Hesse_1$(миноры обозначим $\\delta$):\n",
    "$$\n",
    "Hesse_1 =\n",
    "\\begin{pmatrix}\n",
    "12 & 2 & 2 \\\\\n",
    "2 & 2 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{11} =\n",
    "\\begin{vmatrix}\n",
    "12\n",
    "\\end{vmatrix}\n",
    "= 12\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{12} =\n",
    "\\begin{vmatrix}\n",
    "12 & 2 \\\\\n",
    "2 & 2 \\\\\n",
    "\\end{vmatrix}\n",
    "= 12*2 - 2*2 = 24 - 4 = 20\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{13} =\n",
    "\\begin{vmatrix}\n",
    "12 & 2 & 2 \\\\\n",
    "2 & 2 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{vmatrix}\n",
    "= 12*2*2 + 2*2*0 + 2*0*2 - 2*2*2 -12*0*0 -2*2*2 = 48 + 0 + 0 - 8 - 0 - 8 = 32\n",
    "$$\n",
    "\n",
    "$\\delta_{11} = 12 > 0$, $\\delta_{12} = 20 > 0$, $\\delta_{13} = 32 > 0$, все угловые миноры матрицы $Hesse_1$ положительны, следовательно и сама матрица положительно определена в точке $M_1(1;-2;-1)$, а это значит, что для функции $f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8$ в точке $M_1$ находится минимум.\n",
    "\n",
    "2) Для матрицы $Hesse_2$(миноры обозначим $\\delta$):\n",
    "$$\n",
    "Hesse_2 =\n",
    "\\begin{pmatrix}\n",
    "-4 & 2 & 2 \\\\\n",
    "2 & 2 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{21} =\n",
    "\\begin{vmatrix}\n",
    "-4\n",
    "\\end{vmatrix}\n",
    "= -4\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{22} =\n",
    "\\begin{vmatrix}\n",
    "-4 & 2 \\\\\n",
    "2 & 2 \\\\\n",
    "\\end{vmatrix}\n",
    "= -4*2 - 2*2 = -8 - 4 = -12\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_{23} =\n",
    "\\begin{vmatrix}\n",
    "-4 & 2 & 2 \\\\\n",
    "2 & 2 & 0 \\\\\n",
    "2 & 0 & 2\n",
    "\\end{vmatrix}\n",
    "= -4*2*2 + 2*2*0 + 2*0*2 - 2*2*2 -(-4)*0*0 -2*2*2 = -16 + 0 + 0 - 8 - 0 - 8 = -32\n",
    "$$\n",
    "\n",
    "$\\delta_{21} = -4 < 0$, $\\delta_{22} = -12 < 0$, $\\delta_{23} = -32 < 0$, все угловые миноры матрицы $Hesse_2$ отрицательны. Для того, чтобы матрица была положительно определённой, необходимо, чтобы все её угловые миноры, либо все собственные значения были положительными. А для того, чтобы матрица была отрицательно определённой, необходимо, чтобы знаки угловых миноров чередовались, начиная с отрицательного, либо чтобы все собственные значения были отрицательными. В случае матрицы $Hesse_2$ не выполняются ни первое, ни второе условие, а значит, что для функции $f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8$ точка $M_2(-\\frac{1}{3};-\\frac{2}{3};\\frac{1}{3})$ является седловой, то есть точкой, в которой функция не имеет ни локального минимума, ни локального максимума."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471475bd",
   "metadata": {},
   "source": [
    "### **1.5. Запись результата и выводов**\n",
    "По условиям задачи необходимо было найти экстремум функции $\\hspace{0.5cm}f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8$. \n",
    "\n",
    "Для поиска экстремума необходимо было найти стационарные точки, в которых возможен экстремум. А также классифицировать стационарные точки, чтобы определить существует ли экстремумы в данных точках.\n",
    "\n",
    "В процессе решения были найдены частные производные первого порядка, также были найдены стационарные точки, в которых все производные первого порядка равны нулю $M_1(1;-2;-1)$ и $M_2(-\\frac{1}{3};-\\frac{2}{3};\\frac{1}{3})$.\n",
    "\n",
    "Далее были найдены частные производные второго порядка, а также их значения в стационарных точках. Далее из частных производных второго порядка были составлены матрицы Гессе, в результате анализа которых было выяснено, что для функции $f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8$ в точке $M_1$ находится минимум, так как матрица Гессе в этой точке положительно определена, а точка $M_2(-\\frac{1}{3};-\\frac{2}{3};\\frac{1}{3})$ для функции $f(x, y, z)=2 x^3+2 x y+2 x z+y^2+z^2+2 y-8$ является седловой, то есть точкой, в которой функция не имеет ни локального минимума, ни локального максимума.\n",
    "\n",
    "Условия задачи выполнены, экстремум найден.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38584b7-0da5-4858-9422-ff5bc2b3854f",
   "metadata": {
    "id": "b38584b7-0da5-4858-9422-ff5bc2b3854f"
   },
   "source": [
    "## **Задача 2** \n",
    "\n",
    "### Найдите условные экстремумы функции:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ed820-965b-484d-baab-b2cafebe7479",
   "metadata": {
    "id": "b36ed820-965b-484d-baab-b2cafebe7479"
   },
   "source": [
    "$$\n",
    " f(x, y)=4 x+8 y, y^2-2 x y+5=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1c6f1-d126-4368-a63e-2bbbefffd542",
   "metadata": {
    "id": "2ce1c6f1-d126-4368-a63e-2bbbefffd542"
   },
   "source": [
    "### Вычислите результат самостоятельно (вручную) и с помощью Python. Сравните результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2f664",
   "metadata": {},
   "source": [
    "### **Задача 2(9 баллов)** \n",
    "1) Составление функции множителей Лагранжа - 1 балл\n",
    "2) Вычисление частных производных и составление системы уравнений - 1 балл\n",
    "3) Решение системы вручную - 2 балла\n",
    "4) Реализация вычислений с помощью Python - 2 балла\n",
    "5) Сравнение результатов - 1 балл\n",
    "6) Формулирование итоговых выводов - 2 балла"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b292b9",
   "metadata": {},
   "source": [
    "### **1) Составление функции множителей Лагранжа**\n",
    "\n",
    "Нам необходимо найти экстремумы функции $f(x, y)=4 x+8 y$ при условии $y^2-2 x y+5=0$. Находить экстремумы будем с помощью метода множителей Лагранжа. Для этого необходимо составить функцию Лагранжа, то есть объединить целевую функцию и функцию ограничений внутри одного выражения.\n",
    "\n",
    "$$\n",
    " L(x, y, \\lambda) = 4 x+8 y + \\lambda(y^2-2 x y+5)\n",
    "$$\n",
    "\n",
    "### **2) Вычисление частных производных и составление системы уравнений**\n",
    "\n",
    "Далее порядок решения задачи такой же, как и при поиске безусловного экстремума. Необходимо вычислить частные производные первого порядка функции Лагранжа, приравнять их к нулю, составить из них систему уравнений и решить ее. Решения системы уравнений будут координатами стационарных точек.\n",
    "\n",
    "#### 2.1) Найдем частные производные первого порядка:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{Частная производная первого порядка L от x: }\\hspace{1cm} L'_x &= 4 - \\lambda * 2 * y \\\\\n",
    "\n",
    "\\text{Частная производная первого порядка L от y: }\\hspace{1cm} L'_y &= 8 + \\lambda * 2 * y - \\lambda * 2 * x \\\\\n",
    "\n",
    "\\text{Частная производная первого порядка L от $\\lambda$: }\\hspace{1cm} L'_\\lambda &= y^2-2 x y+5 \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### 2.1) Составим систему уравнений частных производных первого порядка, приравненных к нулю:\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    "    \\begin{cases}\n",
    "        4 - \\lambda 2 y = 0\\\\\n",
    "        8 + \\lambda 2 y - \\lambda 2 x = 0 \\\\\n",
    "        y^2-2 x y+5 = 0\n",
    "    \\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "#### **3) Решение системы вручную**\n",
    "Полученную систему уравнений будем решать методом подстановки.\n",
    "\n",
    "Для начала, ко второму уравнению системы прибавим первое, далее из первого выразим $y$, а из второго $x$, и подставим значения $y$ и $x$ в третье уравнение:\n",
    "$$\n",
    " \\begin{equation}\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        4 - \\lambda 2 y = 0\\\\\n",
    "        8 + \\lambda 2 y - \\lambda 2 x = 0 \\\\\n",
    "        y^2-2 x y+5 = 0\n",
    "    \\end{cases}\n",
    "    \\right\\| (1) + (2) \\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        4 - \\lambda 2 y = 0\\\\\n",
    "        12 - \\lambda 2 x = 0 \\\\\n",
    "        y^2-2 x y+5 = 0\n",
    "    \\end{cases}\n",
    "    \\right. \\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        y = \\frac{2}{\\lambda}\\\\\n",
    "        x = \\frac{6}{\\lambda} \\\\\n",
    "        (\\frac{2}{\\lambda})^2-2 (\\frac{6}{\\lambda}) (\\frac{2}{\\lambda})+5 = 0\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "Для нахождения значения $\\lambda$ необходимо решить квадратное уравнение $(\\frac{2}{\\lambda})^2-2 (\\frac{6}{\\lambda}) (\\frac{2}{\\lambda})+5 = 0$, раскроем скобки и упростим его:\n",
    "$$\n",
    "\\Bigl(\\frac{2}{\\lambda}\\Bigr)^2-2 \\Bigl(\\frac{6}{\\lambda}\\Bigr) \\Bigl(\\frac{2}{\\lambda}\\Bigr)+5 = 0 \n",
    "\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} 4*\\frac{1}{\\lambda^2}-24 *\\frac{1}{\\lambda^2} +5 = 0 \n",
    "\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} \\left.-20 *\\frac{1}{\\lambda^2} = -5 \\right\\|:(-20) \n",
    "\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} \\frac{1}{\\lambda^2} = \\frac{1}{4}\n",
    "\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} \\lambda = \\sqrt[2]{4}\n",
    "\\hspace{0.5cm}\\Rightarrow\\hspace{0.5cm} \\lambda_1 = 2; \\hspace{0.5cm} \\lambda_2 = -2\n",
    "$$\n",
    "\n",
    "Далее найдем значения остальных переменных, подставив значения $\\lambda_1$, $\\lambda_2$ в систему уравнений:\n",
    "\n",
    "1) Для $\\lambda_1 = 2$\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        y = \\frac{2}{2}\\\\\n",
    "        x = \\frac{6}{2} \\\\\n",
    "        (\\frac{2}{2})^2-2 (\\frac{6}{2}) (\\frac{2}{2})+5 = 0\n",
    "    \\end{cases}\n",
    "    \\right.\\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        y = 1\\\\\n",
    "        x = 3 \\\\\n",
    "        0 = 0\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    " \\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_{1} = 3;\\hspace{0.5cm} y_{1} = 1;\\hspace{0.5cm} \\lambda_1 = 2\n",
    "$$\n",
    "2) Для $\\lambda_2 = -2$\n",
    "\n",
    "$$\n",
    " \\begin{equation}\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        y = \\frac{2}{-2}\\\\\n",
    "        x = \\frac{6}{-2} \\\\\n",
    "        (\\frac{2}{-2})^2-2 (\\frac{6}{-2}) (\\frac{2}{-2})+5 = 0\n",
    "    \\end{cases}\n",
    "    \\right.\\Rightarrow\n",
    "    \\left.\n",
    "    \\begin{cases}\n",
    "        y = -1\\\\\n",
    "        x = -3 \\\\\n",
    "        0 = 0\n",
    "    \\end{cases}\n",
    "    \\right.\n",
    " \\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x_{2} = -3;\\hspace{0.5cm} y_{2} = -1;\\hspace{0.5cm} \\lambda_2 = -2\n",
    "$$\n",
    "\n",
    "Получены стационарные точки, назовем их $M_1(3;1)$ и $M_2(-3,-1)$. Для определения точек максимума и минимума найдем значения целевой функции в стационарных точках:\n",
    "1) Для точки $M_1(3;1)$:\n",
    "$$\n",
    "f(3,1) = 4 x+8 y = 4 * 3 + 8 * 1 = 12 + 8 = 20\n",
    "$$\n",
    "1) Для точки $M_2(-3;-1)$:\n",
    "$$\n",
    "f(-3,-1) = 4 x+8 y = 4 * (-3) + 8 * (-1) = -12 + -8 = -20\n",
    "$$\n",
    "\n",
    "Таким образом большее значение $f(M_1) = 20$  - это условный максимум, меньшее значение $f(M_2) = -20$ - это условный минимум.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe3740",
   "metadata": {},
   "source": [
    "#### 4) Реализация вычислений с помощью Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "818929f6-c478-49ad-997e-536d3c4f7f33",
   "metadata": {
    "id": "818929f6-c478-49ad-997e-536d3c4f7f33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Целевая функция для аргументов x и y : f(x,y) =  4*x + 8*y\n",
      "Функция ограничений:  -2*x*y + y**2 + 5 = 0\n",
      "Функция Лагранжа :  l*(-2*x*y + y**2 + 5) + 4*x + 8*y\n",
      "df/dx = -2*l*y + 4 = 0\n",
      "df/dy = l*(-2*x + 2*y) + 8 = 0\n",
      "df/dl = -2*x*y + y**2 + 5 = 0\n",
      "Стационарная точка M1(x,y):\n",
      "( -3.0 ; -1.0 )\n",
      "Стационарная точка M2(x,y):\n",
      "( 3.0 ; 1.0 )\n",
      "Значение целевой функции в точке M1(-3;-1) f(-3,-1) =  -20\n",
      "Значение целевой функции в точке M2(3;1) f(3,1) =  20\n"
     ]
    }
   ],
   "source": [
    "from sympy import *\n",
    "x,y,l=symbols(' x y l' ) # Переменные функции Лагранжа\n",
    "g = 4*x + 8*y \n",
    "print('Целевая функция для аргументов x и y : f(x,y) = ', g)\n",
    "q = y**2 - 2*x*y + 5\n",
    "print('Функция ограничений: ', q,'= 0')\n",
    "f = 4*x + 8*y + l*(y**2 - 2*x*y + 5)\n",
    "print('Функция Лагранжа : ',f)\n",
    "fx = f.diff(x)\n",
    "print('df/dx =',fx,'= 0')\n",
    "fy = f.diff(y)\n",
    "print('df/dy =',fy,'= 0')\n",
    "fl = f.diff(l)\n",
    "print('df/dl =',fl,'= 0')\n",
    "sols = solve([fx,fy,fl],x,y,l)\n",
    "print('Стационарная точка M1(x,y):\\n(',float(sols[0][0]),';',float(sols[0][1]),')')\n",
    "print('Стационарная точка M2(x,y):\\n(',float(sols[1][0]),';',float(sols[1][1]),')')\n",
    "print('Значение целевой функции в точке M1(-3;-1) f(-3,-1) = ',4*(-3) + 8*(-1))\n",
    "print('Значение целевой функции в точке M2(3;1) f(3,1) = ',4*3 + 8*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ba0ad",
   "metadata": {},
   "source": [
    "#### 5) Сравнение результатов\n",
    "При решении системы уравнений вручную получились следующие результаты:\n",
    "\n",
    "$$\n",
    "x_{1} = 3;\\hspace{0.5cm} y_{1} = 1;\\hspace{0.5cm} \\lambda_1 = 2\n",
    "$$\n",
    "$$\n",
    "x_{2} = -3;\\hspace{0.5cm} y_{2} = -1;\\hspace{0.5cm} \\lambda_2 = -2\n",
    "$$\n",
    "Получены стационарные точки $M_1(3;1)$ и $M_2(-3,-1)$\\\n",
    "Найдены значения целевой функции в стационарных точках  $f(M_1) = 20$, $f(M_2) = -20$\n",
    "\n",
    "При реализации вычислений с помощью Python получены идентичные результаты. Что подтверждает вычисления вручную.\n",
    "\n",
    "#### 6) Формулирование итоговых выводов\n",
    "\n",
    "По условиям задачи необходимо было найти экстремум целевой функции $\\hspace{0.5cm} f(x, y)=4 x+8 y$ при условии  $y^2-2 x y+5=0$.\n",
    "\n",
    "Для поиска экстремума необходимо было составить функцию Лагранжа, найти стационарные точки, найти значения целевой функции в стационарных точках для определения условных экстремумов.\n",
    "\n",
    "В процессе решения были найдены частные производные первого порядка, была составлена система уравнений частных производных первого порядка, приравненных к нулю. Решение системы уравнений было реализовано двумя способами: вручную и с помощью Python, оба способа показали идентичные результаты, что косвенно подтверждает правильность вычислений. Также были найдены стационарные точки, в которых определяется условный экстремум функции. Далее найдены значения целевой функции в стационарных точках  $f(M_1) = 20$, $f(M_2) = -20$. Таким образом делаем вывод, что в точке $M_1(3;1)$ находится максимум целевой функции  $f(x, y)=4 x+8 y$ при условии $y^2-2 x y+5=0$, в в точке $M_2(-3,-1)$ находится минимум целевой функции $ f(x, y)=4 x+8 y$ при условии $y^2-2 x y+5=0$.\n",
    "\n",
    "\n",
    "Условия задачи выполнены, условные экстремумы найдены.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818083c3-7318-4669-bb15-5a8a48ef543d",
   "metadata": {
    "id": "818083c3-7318-4669-bb15-5a8a48ef543d"
   },
   "source": [
    "## **Задача 3**\n",
    "\n",
    "Вам предложены данные с информацией о успеваемости студентов:\n",
    "\n",
    "Независимые переменные:\n",
    "* Hours Studied: Общее количество часов, потраченных на учебу каждым студентом.\n",
    "* Previous Scores: Баллы, полученные студентами на предыдущих экзаменах.\n",
    "* Sleep Hours: Среднее количество часов сна студента в сутки.\n",
    "* Sample Question Papers Practiced: Количество пробных экзаменационных работ, с которыми студент занимался.\n",
    "  \n",
    "Целевая переменная:\n",
    "* Performance Index: Показатель общей успеваемости каждого студента. Индекс успеваемости отражает академическую успеваемость студента и округляется до ближайшего целого числа. Индекс варьируется от 10 до 100, при этом более высокие значения свидетельствуют о более высокой успеваемости."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65c2300-43b2-4c43-b762-1e20d29ae889",
   "metadata": {
    "id": "f65c2300-43b2-4c43-b762-1e20d29ae889"
   },
   "source": [
    "**Решите задачу линейной регрессии, реализовав градиентный спуск самостоятельно, не используя готовое решение из какой-либо библиотеки.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad10429",
   "metadata": {},
   "source": [
    "3.1. Формализация задачи линейной регрессии - 1 балл\\\n",
    "3.2. Реализация функции ошибок (потерь) - 2 балла\\\n",
    "3.3. Реализация градиентного спуска - 3 балла\\\n",
    "3.4. Предобработка данных - 1 балл\\\n",
    "Данные подготовлены корректно, отсюда утствие пропусков, нормализация или стандартизация выполнены (если нужно).\n",
    "\n",
    "3.5. Анализ итоговой модели и коэффициентов регрессии - 1 балл\\\n",
    "3.6. Предсказание и оценка точности модели - 1 балл\\\n",
    "3.7. Сравнение с библиотечными решениями Python (sklearn) - 1 балл\\\n",
    "Проведено сравнение собственных расчетов с результатами использования библиотек. Оценена точность совпадения.\n",
    "\n",
    "3.8. Вывод и интерпретация результатов - 1 балл\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8712dbd",
   "metadata": {},
   "source": [
    "### **3.1. Формализация задачи линейной регрессии**\n",
    "Цель: разработать модель линейной регрессии, которая предсказывает \"Performance Index: Показатель общей успеваемости каждого студента\" на основе независимых переменных: \"Hours Studied: Общее количество часов, потраченных на учебу каждым студентом\", \"Previous Scores: Баллы, полученные студентами на предыдущих экзаменах\", \"Sleep Hours: Среднее количество часов сна студента в сутки\", \"Sample Question Papers Practiced: Количество пробных экзаменационных работ, с которыми студент занимался\".\n",
    "\n",
    "Данные представлены в файле \"Student_Performance.txt\", файл содержит данные по 10000 студентов.\n",
    "\n",
    "Мы хотим найти зависимость между Показателем общей успеваемости каждого студента ($y$) и показателями, характеризиющими учебный процесс студентов ($x_1$, $x_2$, $x_3$, $x_4$).\n",
    "\n",
    "Модель: $у = w_0 + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + e$, где\n",
    "\n",
    "1. $y$ - Performance Index: Показатель общей успеваемости каждого студента.\n",
    "2. $x_1$ - Hours Studied: Общее количество часов, потраченных на учебу каждым студентом.\n",
    "3. $x_2$ - Previous Scores: Баллы, полученные студентами на предыдущих экзаменах.\n",
    "4. $x_3$ - Sleep Hours: Среднее количество часов сна студента в сутки.\n",
    "5. $x_4$ - Sample Question Papers Practiced: Количество пробных экзаменационных работ, с которыми студент занимался.\n",
    "6. $w_1$ - коэффициент, показывающий, как изменяется Performance Index при увеличении Hours Studied.\n",
    "7. $w_2$ - коэффициент, показывающий, как изменяется Performance Index при увеличении Previous Scores.\n",
    "8. $w_3$ - коэффициент, показывающий, как изменяется Performance Index при увеличении Sleep Hours.\n",
    "9. $w_4$ - коэффициент, показывающий, как изменяется Performance Index при увеличении Sample Question Papers Practiced.\n",
    "10. $e$ - ошибка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd8d865",
   "metadata": {},
   "source": [
    "### **3.2. Реализация функции ошибок (потерь)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "afd88196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(X, y , weight):\n",
    "    \n",
    "    # Расчет предсказания модели\n",
    "    y_pred = np.dot(X, weight)\n",
    "    \n",
    "    # Расчет значения функции ошибки MSE\n",
    "    error = (y_pred - y)**2\n",
    "    loss = 1/(n)*np.sum(error)\n",
    "  \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c8485",
   "metadata": {},
   "source": [
    "### **3.3. Реализация градиентного спуска**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13f28954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Составляем функцию градиентного спуска\n",
    "def grad_d(X, y, weight, step, iterations):\n",
    "\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        # Предсказание\n",
    "        \n",
    "        y_pred = np.dot(X, weight)\n",
    "        \n",
    "        # Градиент\n",
    "        \n",
    "        grad = (2/n) * ((X.transpose())@(y_pred - y))\n",
    "        \n",
    "        # Обновление весов\n",
    "        \n",
    "        weight -= step * grad\n",
    "        \n",
    "        # Расчёт и сохранение ошибки\n",
    "        \n",
    "        losses.append(loss_function(X, y, weight))\n",
    "\n",
    "    return weight, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d00f295",
   "metadata": {},
   "source": [
    "### **3.4. Предобработка данных**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e1f9a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Hours Studied                     10000 non-null  int64  \n",
      " 1   Previous Scores                   10000 non-null  int64  \n",
      " 2   Extracurricular Activities        10000 non-null  object \n",
      " 3   Sleep Hours                       10000 non-null  int64  \n",
      " 4   Sample Question Papers Practiced  10000 non-null  int64  \n",
      " 5   Performance Index                 10000 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 468.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Загружаем файл с данными. Преобразуем его в датафрейм.\n",
    "\n",
    "df = pd.read_csv('C:\\IDE\\Math analyze\\Student_Performance.txt')\n",
    "\n",
    "#Получаем информацию о датафрейме, в том числе убеждаемся в отсутствии пропусков, так как даный метод указывает эту информацию. \n",
    "\n",
    "df.info()\n",
    "\n",
    "\n",
    "#Определяем признаки\n",
    "X = df[['Hours Studied',\t'Previous Scores',\t'Sleep Hours',\t'Sample Question Papers Practiced']]\n",
    "#print(X)\n",
    "\n",
    "\n",
    "\n",
    "#Определяем целевую переменную\n",
    "y = df['Performance Index']\n",
    "#print(y)\n",
    "\n",
    "# Прибавляем к массиву признаков столбец свободных коэффициентов, также проверяем размерность массива признаков\n",
    "n = len(y)\n",
    "X = np.append(np.ones((n,1)), X.values.reshape(n,4), axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# Задаем необходимую размерность массива целевой переменной\n",
    "y = df['Performance Index'].values.reshape(n,1)\n",
    "#print(y)\n",
    "\n",
    "# Задаем начальное приближение, нулевой вектор размерностью, необходимой для умножения на массив признаков\n",
    "\n",
    "weight = np.zeros((X.shape[1], 1))\n",
    "#print(weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8fe0f0",
   "metadata": {},
   "source": [
    "### Реализация модели линейной регрессии с градиентым спуском"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65ae96f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Hours Studied                     10000 non-null  int64  \n",
      " 1   Previous Scores                   10000 non-null  int64  \n",
      " 2   Extracurricular Activities        10000 non-null  object \n",
      " 3   Sleep Hours                       10000 non-null  int64  \n",
      " 4   Sample Question Papers Practiced  10000 non-null  int64  \n",
      " 5   Performance Index                 10000 non-null  float64\n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 468.9+ KB\n",
      "grad_d_weights [[55.31149999]\n",
      " [ 7.40240354]\n",
      " [17.63809533]\n",
      " [ 0.80387754]\n",
      " [ 0.54854088]]\n",
      "\n",
      "skl_weights [[ 0.          7.40240354 17.63809533  0.80387754  0.54854088]]\n",
      "\n",
      "skl_w_0 [55.3115]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'regression_metrics_train'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'MSE': 4.262289072936616,\n",
       " 'RMSE': np.float64(2.064531199312962),\n",
       " 'R²': 0.9884388348325367}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'regression_metrics_test'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'MSE': 4.182254914221027,\n",
       " 'RMSE': np.float64(2.0450562129733814),\n",
       " 'R²': 0.9887144552394246}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# данные, предобработка, моделирование\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "# метрики\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score\n",
    ")\n",
    "\n",
    "np.random.seed(28)\n",
    "\n",
    "\n",
    "#Загружаем файл с данными. Преобразуем его в датафрейм.\n",
    "\n",
    "df = pd.read_csv('C:\\IDE\\Math analyze\\Student_Performance.txt')\n",
    "\n",
    "#Получаем информацию о датафрейме, в том числе убеждаемся в отсутствии пропусков, так как даный метод указывает эту информацию. \n",
    "\n",
    "df.info()\n",
    "\n",
    "\n",
    "#Определяем признаки\n",
    "X = df[['Hours Studied',\t'Previous Scores',\t'Sleep Hours',\t'Sample Question Papers Practiced']]\n",
    "\n",
    "#Определяем целевую переменную\n",
    "y = df['Performance Index']\n",
    "\n",
    "# Разделим на train и test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Стандартизируем данные\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Прибавляем к массивам признаков столбец свободных коэффициентов, также проверяем размерность массивов признаков\n",
    "n_train = len(y_train)\n",
    "n_test = len(y_test)\n",
    "X_train = np.append(np.ones((n_train,1)), X_train.reshape(n_train,4), axis = 1)\n",
    "X_test = np.append(np.ones((n_test,1)), X_test.reshape(n_test,4), axis = 1)\n",
    "\n",
    "# Задаем необходимую размерность массива целевой переменной\n",
    "y_train = y_train.values.reshape(n_train,1)\n",
    "y_test = y_test.values.reshape(n_test,1)\n",
    "\n",
    "# Задаем начальное приближение, нулевой вектор размерностью, необходимой для умножения на массив признаков\n",
    "weights = np.zeros((X_train.shape[1], 1))\n",
    "\n",
    "# Составляем функцию ошибок(потерь)\n",
    "def loss_function(X, y , weights):\n",
    "    \n",
    "    # Расчет предсказания модели\n",
    "    y_pred = np.dot(X, weights)\n",
    "    \n",
    "    # Расчет значения функции ошибки MSE\n",
    "    error = (y_pred - y)**2\n",
    "    loss = 1/(n)*np.sum(error)\n",
    "  \n",
    "    return loss\n",
    "\n",
    "# Составляем функцию градиентного спуска\n",
    "def grad_d(X, y, weights, step, iterations):\n",
    "    losses = []\n",
    "    for i in range(iterations):\n",
    "        # Предсказание\n",
    "        y_pred = np.dot(X, weights)\n",
    "        \n",
    "        # Градиент\n",
    "        grad = (2/n) * ((X.transpose())@(y_pred - y))\n",
    "        \n",
    "        # Обновление весов\n",
    "        weights -= step * grad\n",
    "        \n",
    "        #расчет и сохранение ошибки\n",
    "        losses.append(loss_function(X, y, weights))\n",
    "\n",
    "    return weights, losses\n",
    "\n",
    "weights, losses_opt = grad_d(X_train, y_train, weights, 0.00018, 80000)\n",
    "\n",
    "print('grad_d_weights', weights)\n",
    "print()\n",
    "\n",
    "# Линейная регрессия с помощью sklearn\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print('skl_weights', model.coef_)\n",
    "print()\n",
    "print('skl_w_0', model.intercept_)\n",
    "\n",
    "# считаем предсказания на train и test\n",
    "p_gd_train = X_train @ weights\n",
    "p_gd_test = X_test @ weights\n",
    "\n",
    "# Вычисляем метрики качества линейной регрессии\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Вычисляет метрики качества линейной регрессии.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like\n",
    "        Реальные значения (таргет).\n",
    "    y_pred : array-like\n",
    "        Предсказанные значения.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Словарь с метриками: MSE, RMSE,  R².\n",
    "    \"\"\"\n",
    "\n",
    "    # MSE\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    # RMSE\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # R^2\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    return {\n",
    "        \"MSE\": mse,\n",
    "        \"RMSE\": rmse,\n",
    "        \"R²\": r2\n",
    "    }\n",
    "    \n",
    "display('regression_metrics_train', regression_metrics(y_train, p_gd_train))\n",
    "print()\n",
    "display('regression_metrics_test', regression_metrics(y_test, p_gd_test))\n",
    "\n",
    "# График сходимости градиентного спуска\n",
    "def plot_history(losses):\n",
    "    \"\"\"\n",
    "    Визуализация графика сходимости\n",
    "    (значение losses в зависимости от номера итерации)\n",
    "    \"\"\"\n",
    "    plt.plot(losses)\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(\"График сходимости градиентного спуска\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(losses_opt)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11be392",
   "metadata": {},
   "source": [
    "### **3.5. Анализ итоговой модели и коэффициентов регрессии**\n",
    "По результатам расчетов получилась модель линейной регрессии, вида\n",
    "Модель: $у = 55.3114999 + w X + 4.262289072936616$, где\n",
    "\n",
    "$$\n",
    "y =\n",
    "55.3114999 +\n",
    "\\begin{pmatrix}\n",
    "7.40240352 \\\\\n",
    "17.63809529\\\\\n",
    "0.80387754\\\\\n",
    "0.54854089\n",
    "\\end{pmatrix}\n",
    "*X\n",
    "+4.262289072936616\n",
    "\n",
    "$$\n",
    "$X$ - вектор характеристик, влияющий на учебу.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff7d7d",
   "metadata": {},
   "source": [
    "### **3.6. Предсказание и оценка точности модели**\n",
    "\n",
    "В процессе рассчетов были вычисленны метрики качества линейной регрессии.\\\n",
    "$MSE$ - Вычисляет среднюю квадратическую разницу между предсказанными и фактическими значениями.\\\n",
    "$RMSE$ - Является квадратным корнем из MSE. Имеет ту же единицу измерения, что и целевая переменная, что делает её более интерпретируемой, чем MSE.\\\n",
    "$R²$ - Показывает долю дисперсии зависимой переменной, которую может объяснить модель.Значение 1 означает, что модель идеально объясняет все вариации данных, а 0 — что модель не объясняет ничего.\n",
    "1. Метрики, вычисленные на тренировочном массиве данных\\\n",
    "$MSE: 4.262289072936627$ \\\n",
    "$RMSE:2.0645311993129645$ \\\n",
    "$R²: 0.9884388348325367$  \n",
    "\n",
    "2. Метрики, вычисленные на тестовом массиве данных\\\n",
    "$MSE: 4.182254907877153$\\\n",
    "$RMSE:2.0450562114223545$\\\n",
    "$R²: 0.9887144552565431$\n",
    "\n",
    "Итого средняя разница между предсказанными и фактическими значениями Performance Index: Показателя общей успеваемости каждого студента составляет ок. 2.065 балла для тренировочной выборки данных и ок. 2.045 балла для тестовой выборки. Также иетрика $R^2$ показывает точность предсказания модели на 98.84 % для тренировочной выборки данных и 98.87 для тестовой выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ffa5ee",
   "metadata": {},
   "source": [
    "### **3.7. Сравнение с библиотечными решениями Python (sklearn)**\n",
    "Проведено сравнение собственных расчетов с результатами использования библиотек. Оценена точность совпадения.\\\n",
    "1.Собственная модель вычислила следующие коэффициенты линейной регрессии (при количестве итераций - 80 000):\n",
    "$$\n",
    "w =\n",
    "\\begin{pmatrix}\n",
    "55.3114999 \\\\\n",
    "7.40240354 \\\\\n",
    "17.63809533\\\\\n",
    "0.80387754\\\\\n",
    "0.54854088\n",
    "\\end{pmatrix}\n",
    "\\text{ - вектор коэффициентов линейной регрессии}\n",
    "$$\n",
    "\n",
    "2. С помощью библиотеки Python (sklearn) были получены следующие коэффициенты линейной регрессии:\n",
    "$$\n",
    "w =\n",
    "\\begin{pmatrix}\n",
    "55.3115 \\\\\n",
    "7.40240354 \\\\\n",
    "17.63809533\\\\\n",
    "0.80387754\\\\\n",
    "0.54854088\n",
    "\\end{pmatrix}\n",
    "\\text{ - вектор коэффициентов линейной регрессии}\n",
    "$$\n",
    "\n",
    "Обе модели показали идентичные результаты с точностью 8 знака после запятой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a65bd6",
   "metadata": {},
   "source": [
    "### **3.8. Вывод и интерпретация результатов**\n",
    "В процессе решения задачи была построена модель линейной регрессии с градиентным спуском для предсказания Показателя общей успеваемости каждого студента. В процессе расчетов получились следующие коэффициенты линейной регрессии.\n",
    "$$\n",
    "w =\n",
    "\\begin{pmatrix}\n",
    "55.3114999 \\\\\n",
    "7.40240354 \\\\\n",
    "17.63809533\\\\\n",
    "0.80387754\\\\\n",
    "0.54854088\n",
    "\\end{pmatrix}\n",
    "\\text{ - вектор коэффициентов линейной регрессии}\n",
    "$$\n",
    "\n",
    "$w_0 = 55.3114999$ - Представляет собой ожидаемое среднее значение Показателя общей успеваемости каждого студента, когда все независимые переменные равны нулю.\\\n",
    "$w_1 = 7.40240354$ - Показывает, на сколько единиц изменится Показатель общей успеваемости каждого студента при увеличении Общеее количествf часов, потраченных на учебу каждым студентом на одну единицу, при условии, что все остальные независимые переменные остаются неизменными.\\\n",
    "$w_2 = 17.63809533$ - Показывает, на сколько единиц изменится Показатель общей успеваемости каждого студента при увеличении Баллов, полученных студентами на предыдущих экзаменах на одну единицу, при условии, что все остальные независимые переменные остаются неизменными.\\\n",
    "$w_3 = 0.80387754$ - Показывает, на сколько единиц изменится Показатель общей успеваемости каждого студента при увеличении Среднего количества часов сна студента в сутки на одну единицу, при условии, что все остальные независимые переменные остаются неизменными.\\\n",
    "$w_4 = 0.54854088$ - Показывает, на сколько единиц изменится Показатель общей успеваемости каждого студента при увеличении Количества пробных экзаменационных работ, с которыми студент занимался на одну единицу, при условии, что все остальные независимые переменные остаются неизменными.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
